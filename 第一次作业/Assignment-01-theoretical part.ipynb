{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Put your answer here}\n",
    "1. 语音识别（智能机器人，实现智能对话，执行相关操作）\n",
    "2. 购物推荐（通过浏览的商品，推荐相关，或顾客可能感兴趣的商品）\n",
    "3. 智能医疗（根据病人的病情描述，得到相关病因结果，并提供治疗方案）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Put your answer here}\n",
    "1. 将 Github 作为管理代码的工具，或者说“仓库”，可以把完成的项目代码放到 GitHub 上。如同 Git，大家可以在上面找到开源代码，共同学习进步。GitHub 也可以记录每天的动态，监督自己的学习情况。\n",
    "2. Jupyter notebook 是一个交互式笔记本，支持多种编程语言，便于创建和共享程序文档，能编写实时代码，数学方程，markdown 等，可用于数据清理和转换，数值模拟，统计建模，机器学习等，是良好的学习工具。\n",
    "3. Pycharm 可以使我们在使用 Python 语言开发时，提高效率的工具，其功能包括：调试、语法高亮、智能提醒、自动完成等。是很好的开发工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "统计模型指以概率论为基础，采用数学统计方法建立的模型。**有些过程无法用理论分析方法导出其模型，但可通过试验测定数据，经过数理统计法求得各变量之间的函数关系，称为统计模型**。常用的数理统计分析方法有最大事后概率估算法、最大似然率辨识法等。常用的统计模型有一般线性模型、广义线性模型和混合模型。统计模型的意义在对大量随机事件的规律性做推断时仍然具有统计性，因而称为统计推断。\n",
    "（参考百度百科）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. 决策树模型（分类），对实例进行分类的树形结构模型，可看作是在给定特征取值条件下的类的概率分布的结果。从根节点到叶节点的每一条路径都可看作是一个条件概率分布，即在特征随机变量 X 取值结果的条件下，分类类别的结果 Y 的概率分布情况。具体场景如：医疗诊断结果，银行贷款时信用度分析。\n",
    "2. K-means模型（聚类），预先设定 K 个聚类，然后不断更新聚类中心，目标是让所有数据点到其所属聚类中心距离的平方（数据集的均值）和趋于稳定。具体场景如：用户类型分类，全球气候区域划分。\n",
    "3. 因子分析模型（降维），在许多变量中找出隐藏的具有代表性的因子，将相同本质的变量归入一个因子，可减少变量的数目，降低样本维度。具体场景如：用户价值评估，学生学习积极性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. 机器学习经常要处理很多不确定量，就比如 NLP 中想要词与词之间的关联程度，这涉及到语义关系，语法等等，特殊词语还有特定的使用习惯和场景，这些都很难总结并结合算法解决实际的问题。于是就提出使用概率的方法，事件的概率是衡量该事件发生的可能性的度量，虽然在一次随机试验中某个事件发生是带有偶然性的，但那些可在相同条件下大量重复的随机试验却往往呈现出明显的数量规律。当我们使用足够大的语料库时，词和词之间的紧密程度就可以用概率来表示。\n",
    "2. 很难用一种模式将所有情况概括完全，并且这种模式下出来的结果不一定是完全正确的，有一定的错误率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "语言模型是根据语言客观事实而进行的语言抽象数学建模，是一种对应关系。语言模型与语言客观事实之间的关系，如同数学上的抽象直线与具体直线之间的关系。语言模型是一个单纯的、统一的、抽象的形式系统，语言客观事实经过语言模型的描述，比较适合于电子计算机进行自动处理，因而语言模型对于自然语言的信息处理具有重大的意义。语言模型其实就是看一句话是不是正常人说出来的（判断自然语言上下文相关的特性）。在很多NLP任务中都会用到，比如机器翻译、语音识别得到若干候选之后。语言模型形式化的描述就是给定一个字符串，看它是自然语言的概率 。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "语言模型可以对一段文本的概率进行估计，对信息检索，机器翻译，语音识别等任务有着重要的作用。\n",
    "其中 n-Gram（有时也称为n元模型）是自然语言处理中一个非常重要的概念，通常在NLP中，它主要有两个重要应用场景：\n",
    "1. 人们基于一定的语料库，可以利用 n-Gram 来预计或者评估一个句子是否合理。\n",
    "\n",
    "2. 另外一方面，n-Gram 的另外一个作用是用来评估两个字符串之间的差异程度。这是模糊匹配中常用的一种手段。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "一元语言模型（ Unigram models ），它是一种上下文无关模型，把句子分成一个一个的词语。该模型只考虑当前词本身出现的概率，而不考虑当前词的上下文环境。概率形式为：\n",
    "$$ P(w_1,w_2,\\cdots,w_n)=P(w_1)\\cdot P(w_2) \\cdots  P(w_n),$$\n",
    "即一个句子出现的概率等于句子中每个单词概率乘积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. 方便计算和理解\n",
    "2. 该模型没有考虑词语在上下文的关系，缺少语义分析，得到的结果不够准确。\n",
    "\n",
    "一元语言模型概率估计的分子和分母都不会出现 0 的情况，因此这个概率估计就非常好定义，并且该值是永远大于 0（我们假设每个词在训练语料库中出现的次数至少一次，这个假设是可信的）。但是，一元语言模型完全的忽视了上下文信息，也就是说丢弃了很多有价值的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans：\n",
    "2元语言模型是求两个词在语料库中出现的概率，具体如下：\n",
    "$$ P(w_1,w_2,...,w_n) = \\prod_{i=1}^n P(w_i|w_{i-1})$$\n",
    "\n",
    "( n-gram 模型也称为n-1阶马尔科夫模型，它的一个假设是：当前词的出现概率仅仅与前面 n-1 个词相关。)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
